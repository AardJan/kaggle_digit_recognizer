{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transform(X, y_hat=None):\n",
    "    \n",
    "    if y_hat is not None:\n",
    "        #DATA\n",
    "        # Convert to numpy.ndarray and change shape to chanel x size x size\n",
    "        X = X.values.reshape(-1,1,28,28)\n",
    "        # Convert numpy.ndarrray to torch tensor\n",
    "        X = torch.from_numpy(X)\n",
    "        # Normalize step 1  change to [0 to 1]\n",
    "        X = torch.true_divide(X, 255)\n",
    "        # Normalize step 2 change to [-1 to 1]\n",
    "        X = torch.true_divide((X - 0.5), 0.5)\n",
    "\n",
    "        # LABELS\n",
    "        # Transform to Tensor\n",
    "        y_hat = torch.from_numpy(y_hat.values)\n",
    "        y_hat.type(torch.LongTensor)\n",
    "    \n",
    "        return X, y_hat\n",
    "    \n",
    "    else:\n",
    "        # DATA\n",
    "        # Convert to numpy.ndarray and change shape to chanel x size x size\n",
    "        X = X.values.reshape(-1,1,28,28)\n",
    "        # Convert numpy.ndarrray to torch tensor\n",
    "        X = torch.from_numpy(X)\n",
    "        # Normalize step 1  change to [0 to 1]\n",
    "        X = torch.true_divide(X, 255)\n",
    "        # Normalize step 2 change to [-1 to 1]\n",
    "        X = torch.true_divide((X - 0.5), 0.5)\n",
    "        \n",
    "        return X    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"data/train.csv\")\n",
    "data_test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5',\n",
       "       'pixel6', 'pixel7', 'pixel8',\n",
       "       ...\n",
       "       'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779',\n",
       "       'pixel780', 'pixel781', 'pixel782', 'pixel783'],\n",
       "      dtype='object', length=785)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data to valid and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = data_train.drop(columns=[\"label\"])\n",
    "y_raw = data_train[\"label\"]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_raw, y_raw, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transform, y_train_transform = data_transform(X=X_train, y_hat=y_train)\n",
    "X_valid_transform, y_valid_transform = data_transform(X=X_valid, y_hat=y_valid)\n",
    "\n",
    "X_test_transform = data_transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TensorDataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "data_train = torch.utils.data.TensorDataset(X_train_transform, y_train_transform)\n",
    "data_valid = torch.utils.data.TensorDataset(X_valid_transform, y_valid_transform)\n",
    "\n",
    "loader_train = torch.utils.data.DataLoader(data_train, batch_size=batch_size)\n",
    "loader_valid = torch.utils.data.DataLoader(data_valid, batch_size=batch_size)\n",
    "\n",
    "\n",
    "data_test = torch.utils.data.TensorDataset(X_test_transform)\n",
    "loader_test = torch.utils.data.DataLoader(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNNModel, self).__init__()\n",
    "        \n",
    "        # 28x28x1\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        # 14x14x16\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        # 7x7x32\n",
    "        #self.conv3 = nn.Conv2d(16, 64, 3, padding=1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        # deep of last Conv2d and \n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #x = self.pool(F.relu(self.conv3(x)))\n",
    "        \n",
    "        x = x.view(-1, 32 * 7 * 7)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        \n",
    "        return x     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNNModel(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1568, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MyNNModel()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.002)\n",
    "criterion = nn.NLLLoss()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 2.169466\tValidation Loss: 1.825376\n",
      "Validation loss decreased (inf --> 1.825376).Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janya\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:402: UserWarning: Couldn't retrieve source code for container of type MyNNModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 1.110605\tValidation Loss: 0.566748\n",
      "Validation loss decreased (1.825376 --> 0.566748).Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.546234\tValidation Loss: 0.385160\n",
      "Validation loss decreased (0.566748 --> 0.385160).Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.428308\tValidation Loss: 0.313938\n",
      "Validation loss decreased (0.385160 --> 0.313938).Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.359904\tValidation Loss: 0.269806\n",
      "Validation loss decreased (0.313938 --> 0.269806).Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.311376\tValidation Loss: 0.236580\n",
      "Validation loss decreased (0.269806 --> 0.236580).Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 0.277198\tValidation Loss: 0.211786\n",
      "Validation loss decreased (0.236580 --> 0.211786).Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 0.243445\tValidation Loss: 0.191822\n",
      "Validation loss decreased (0.211786 --> 0.191822).Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.224200\tValidation Loss: 0.174080\n",
      "Validation loss decreased (0.191822 --> 0.174080).Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.204462\tValidation Loss: 0.158849\n",
      "Validation loss decreased (0.174080 --> 0.158849).Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.188087\tValidation Loss: 0.149457\n",
      "Validation loss decreased (0.158849 --> 0.149457).Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.176830\tValidation Loss: 0.138070\n",
      "Validation loss decreased (0.149457 --> 0.138070).Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.166761\tValidation Loss: 0.129070\n",
      "Validation loss decreased (0.138070 --> 0.129070).Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.156802\tValidation Loss: 0.122853\n",
      "Validation loss decreased (0.129070 --> 0.122853).Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.149395\tValidation Loss: 0.115413\n",
      "Validation loss decreased (0.122853 --> 0.115413).Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.139863\tValidation Loss: 0.110305\n",
      "Validation loss decreased (0.115413 --> 0.110305).Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.133078\tValidation Loss: 0.104524\n",
      "Validation loss decreased (0.110305 --> 0.104524).Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.129306\tValidation Loss: 0.100722\n",
      "Validation loss decreased (0.104524 --> 0.100722).Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.121167\tValidation Loss: 0.096664\n",
      "Validation loss decreased (0.100722 --> 0.096664).Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.116660\tValidation Loss: 0.092464\n",
      "Validation loss decreased (0.096664 --> 0.092464).Saving model ...\n",
      "Epoch: 21 \tTraining Loss: 0.115666\tValidation Loss: 0.089633\n",
      "Validation loss decreased (0.092464 --> 0.089633).Saving model ...\n",
      "Epoch: 22 \tTraining Loss: 0.111183\tValidation Loss: 0.086516\n",
      "Validation loss decreased (0.089633 --> 0.086516).Saving model ...\n",
      "Epoch: 23 \tTraining Loss: 0.104497\tValidation Loss: 0.083194\n",
      "Validation loss decreased (0.086516 --> 0.083194).Saving model ...\n",
      "Epoch: 24 \tTraining Loss: 0.102607\tValidation Loss: 0.081496\n",
      "Validation loss decreased (0.083194 --> 0.081496).Saving model ...\n",
      "Epoch: 25 \tTraining Loss: 0.098381\tValidation Loss: 0.078407\n",
      "Validation loss decreased (0.081496 --> 0.078407).Saving model ...\n",
      "Epoch: 26 \tTraining Loss: 0.095807\tValidation Loss: 0.077020\n",
      "Validation loss decreased (0.078407 --> 0.077020).Saving model ...\n",
      "Epoch: 27 \tTraining Loss: 0.092438\tValidation Loss: 0.073846\n",
      "Validation loss decreased (0.077020 --> 0.073846).Saving model ...\n",
      "Epoch: 28 \tTraining Loss: 0.089788\tValidation Loss: 0.072032\n",
      "Validation loss decreased (0.073846 --> 0.072032).Saving model ...\n",
      "Epoch: 29 \tTraining Loss: 0.088287\tValidation Loss: 0.071339\n",
      "Validation loss decreased (0.072032 --> 0.071339).Saving model ...\n",
      "Epoch: 30 \tTraining Loss: 0.085696\tValidation Loss: 0.069504\n",
      "Validation loss decreased (0.071339 --> 0.069504).Saving model ...\n",
      "Epoch: 31 \tTraining Loss: 0.085275\tValidation Loss: 0.067225\n",
      "Validation loss decreased (0.069504 --> 0.067225).Saving model ...\n",
      "Epoch: 32 \tTraining Loss: 0.082895\tValidation Loss: 0.066232\n",
      "Validation loss decreased (0.067225 --> 0.066232).Saving model ...\n",
      "Epoch: 33 \tTraining Loss: 0.081004\tValidation Loss: 0.064701\n",
      "Validation loss decreased (0.066232 --> 0.064701).Saving model ...\n",
      "Epoch: 34 \tTraining Loss: 0.078462\tValidation Loss: 0.063476\n",
      "Validation loss decreased (0.064701 --> 0.063476).Saving model ...\n",
      "Epoch: 35 \tTraining Loss: 0.077214\tValidation Loss: 0.062214\n",
      "Validation loss decreased (0.063476 --> 0.062214).Saving model ...\n",
      "Epoch: 36 \tTraining Loss: 0.072647\tValidation Loss: 0.061435\n",
      "Validation loss decreased (0.062214 --> 0.061435).Saving model ...\n",
      "Epoch: 37 \tTraining Loss: 0.072939\tValidation Loss: 0.060303\n",
      "Validation loss decreased (0.061435 --> 0.060303).Saving model ...\n",
      "Epoch: 38 \tTraining Loss: 0.072382\tValidation Loss: 0.058753\n",
      "Validation loss decreased (0.060303 --> 0.058753).Saving model ...\n",
      "Epoch: 39 \tTraining Loss: 0.071509\tValidation Loss: 0.057366\n",
      "Validation loss decreased (0.058753 --> 0.057366).Saving model ...\n",
      "Epoch: 40 \tTraining Loss: 0.071528\tValidation Loss: 0.056683\n",
      "Validation loss decreased (0.057366 --> 0.056683).Saving model ...\n",
      "Epoch: 41 \tTraining Loss: 0.068770\tValidation Loss: 0.055814\n",
      "Validation loss decreased (0.056683 --> 0.055814).Saving model ...\n",
      "Epoch: 42 \tTraining Loss: 0.067697\tValidation Loss: 0.055077\n",
      "Validation loss decreased (0.055814 --> 0.055077).Saving model ...\n",
      "Epoch: 43 \tTraining Loss: 0.064262\tValidation Loss: 0.054568\n",
      "Validation loss decreased (0.055077 --> 0.054568).Saving model ...\n",
      "Epoch: 44 \tTraining Loss: 0.063508\tValidation Loss: 0.053632\n",
      "Validation loss decreased (0.054568 --> 0.053632).Saving model ...\n",
      "Epoch: 45 \tTraining Loss: 0.063099\tValidation Loss: 0.052533\n",
      "Validation loss decreased (0.053632 --> 0.052533).Saving model ...\n",
      "Epoch: 46 \tTraining Loss: 0.061406\tValidation Loss: 0.052043\n",
      "Validation loss decreased (0.052533 --> 0.052043).Saving model ...\n",
      "Epoch: 47 \tTraining Loss: 0.063767\tValidation Loss: 0.051588\n",
      "Validation loss decreased (0.052043 --> 0.051588).Saving model ...\n",
      "Epoch: 48 \tTraining Loss: 0.061156\tValidation Loss: 0.050942\n",
      "Validation loss decreased (0.051588 --> 0.050942).Saving model ...\n",
      "Epoch: 49 \tTraining Loss: 0.058794\tValidation Loss: 0.050112\n",
      "Validation loss decreased (0.050942 --> 0.050112).Saving model ...\n",
      "Epoch: 50 \tTraining Loss: 0.058660\tValidation Loss: 0.049865\n",
      "Validation loss decreased (0.050112 --> 0.049865).Saving model ...\n",
      "Epoch: 51 \tTraining Loss: 0.057985\tValidation Loss: 0.048957\n",
      "Validation loss decreased (0.049865 --> 0.048957).Saving model ...\n",
      "Epoch: 52 \tTraining Loss: 0.055534\tValidation Loss: 0.047870\n",
      "Validation loss decreased (0.048957 --> 0.047870).Saving model ...\n",
      "Epoch: 53 \tTraining Loss: 0.057443\tValidation Loss: 0.048043\n",
      "Epoch: 54 \tTraining Loss: 0.055351\tValidation Loss: 0.046534\n",
      "Validation loss decreased (0.047870 --> 0.046534).Saving model ...\n",
      "Epoch: 55 \tTraining Loss: 0.054707\tValidation Loss: 0.046716\n",
      "Epoch: 56 \tTraining Loss: 0.053896\tValidation Loss: 0.045808\n",
      "Validation loss decreased (0.046534 --> 0.045808).Saving model ...\n",
      "Epoch: 57 \tTraining Loss: 0.053111\tValidation Loss: 0.045992\n",
      "Epoch: 58 \tTraining Loss: 0.051604\tValidation Loss: 0.045086\n",
      "Validation loss decreased (0.045808 --> 0.045086).Saving model ...\n",
      "Epoch: 59 \tTraining Loss: 0.050916\tValidation Loss: 0.044553\n",
      "Validation loss decreased (0.045086 --> 0.044553).Saving model ...\n",
      "Epoch: 60 \tTraining Loss: 0.052034\tValidation Loss: 0.044455\n",
      "Validation loss decreased (0.044553 --> 0.044455).Saving model ...\n",
      "Epoch: 61 \tTraining Loss: 0.050210\tValidation Loss: 0.044284\n",
      "Validation loss decreased (0.044455 --> 0.044284).Saving model ...\n",
      "Epoch: 62 \tTraining Loss: 0.049439\tValidation Loss: 0.043018\n",
      "Validation loss decreased (0.044284 --> 0.043018).Saving model ...\n",
      "Epoch: 63 \tTraining Loss: 0.049626\tValidation Loss: 0.042813\n",
      "Validation loss decreased (0.043018 --> 0.042813).Saving model ...\n",
      "Epoch: 64 \tTraining Loss: 0.049802\tValidation Loss: 0.042606\n",
      "Validation loss decreased (0.042813 --> 0.042606).Saving model ...\n",
      "Epoch: 65 \tTraining Loss: 0.047246\tValidation Loss: 0.041749\n",
      "Validation loss decreased (0.042606 --> 0.041749).Saving model ...\n",
      "Epoch: 66 \tTraining Loss: 0.047006\tValidation Loss: 0.041586\n",
      "Validation loss decreased (0.041749 --> 0.041586).Saving model ...\n",
      "Epoch: 67 \tTraining Loss: 0.046798\tValidation Loss: 0.041105\n",
      "Validation loss decreased (0.041586 --> 0.041105).Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68 \tTraining Loss: 0.046807\tValidation Loss: 0.041504\n",
      "Epoch: 69 \tTraining Loss: 0.046155\tValidation Loss: 0.041562\n",
      "Epoch: 70 \tTraining Loss: 0.045170\tValidation Loss: 0.040377\n",
      "Validation loss decreased (0.041105 --> 0.040377).Saving model ...\n",
      "Epoch: 71 \tTraining Loss: 0.044475\tValidation Loss: 0.040150\n",
      "Validation loss decreased (0.040377 --> 0.040150).Saving model ...\n",
      "Epoch: 72 \tTraining Loss: 0.044712\tValidation Loss: 0.040208\n",
      "Epoch: 73 \tTraining Loss: 0.043988\tValidation Loss: 0.039815\n",
      "Validation loss decreased (0.040150 --> 0.039815).Saving model ...\n",
      "Epoch: 74 \tTraining Loss: 0.043757\tValidation Loss: 0.039166\n",
      "Validation loss decreased (0.039815 --> 0.039166).Saving model ...\n",
      "Epoch: 75 \tTraining Loss: 0.042413\tValidation Loss: 0.039183\n",
      "Epoch: 76 \tTraining Loss: 0.041893\tValidation Loss: 0.038639\n",
      "Validation loss decreased (0.039166 --> 0.038639).Saving model ...\n",
      "Epoch: 77 \tTraining Loss: 0.042013\tValidation Loss: 0.038622\n",
      "Validation loss decreased (0.038639 --> 0.038622).Saving model ...\n",
      "Epoch: 78 \tTraining Loss: 0.042867\tValidation Loss: 0.039078\n",
      "Epoch: 79 \tTraining Loss: 0.040849\tValidation Loss: 0.038536\n",
      "Validation loss decreased (0.038622 --> 0.038536).Saving model ...\n",
      "Epoch: 80 \tTraining Loss: 0.040356\tValidation Loss: 0.038052\n",
      "Validation loss decreased (0.038536 --> 0.038052).Saving model ...\n",
      "Epoch: 81 \tTraining Loss: 0.038598\tValidation Loss: 0.037146\n",
      "Validation loss decreased (0.038052 --> 0.037146).Saving model ...\n",
      "Epoch: 82 \tTraining Loss: 0.039653\tValidation Loss: 0.037438\n",
      "Epoch: 83 \tTraining Loss: 0.040049\tValidation Loss: 0.037160\n",
      "Epoch: 84 \tTraining Loss: 0.039921\tValidation Loss: 0.037126\n",
      "Validation loss decreased (0.037146 --> 0.037126).Saving model ...\n",
      "Epoch: 85 \tTraining Loss: 0.038320\tValidation Loss: 0.036850\n",
      "Validation loss decreased (0.037126 --> 0.036850).Saving model ...\n",
      "Epoch: 86 \tTraining Loss: 0.039099\tValidation Loss: 0.036272\n",
      "Validation loss decreased (0.036850 --> 0.036272).Saving model ...\n",
      "Epoch: 87 \tTraining Loss: 0.038561\tValidation Loss: 0.035919\n",
      "Validation loss decreased (0.036272 --> 0.035919).Saving model ...\n",
      "Epoch: 88 \tTraining Loss: 0.037696\tValidation Loss: 0.036647\n",
      "Epoch: 89 \tTraining Loss: 0.036784\tValidation Loss: 0.035720\n",
      "Validation loss decreased (0.035919 --> 0.035720).Saving model ...\n",
      "Epoch: 90 \tTraining Loss: 0.036145\tValidation Loss: 0.035439\n",
      "Validation loss decreased (0.035720 --> 0.035439).Saving model ...\n",
      "Test Accuracy of     0: 99% (72933/73440)\n",
      "Test Accuracy of     1: 99% (81395/81810)\n",
      "Test Accuracy of     2: 96% (73592/76140)\n",
      "Test Accuracy of     3: 95% (80845/84330)\n",
      "Test Accuracy of     4: 97% (73260/75510)\n",
      "Test Accuracy of     5: 95% (60421/63180)\n",
      "Test Accuracy of     6: 98% (69508/70650)\n",
      "Test Accuracy of     7: 97% (78506/80370)\n",
      "Test Accuracy of     8: 95% (71938/75150)\n",
      "Test Accuracy of     9: 95% (72120/75420)\n",
      "\n",
      "Test Accuracy (Overall): 97% (734518/756000)\n"
     ]
    }
   ],
   "source": [
    "epochs = 90\n",
    "valid_loss_min = np.Inf\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    \n",
    "    # track loss\n",
    "    loss_train = 0.0\n",
    "    loss_valid = 0.0\n",
    "    \n",
    "    # enable model to train not evaluate (turn on dropout)\n",
    "    model.train() \n",
    "    for pic, target in loader_train:\n",
    "        if torch.cuda.is_available():\n",
    "            pic, target = pic.cuda(), target.cuda()\n",
    "        #clear gradient    \n",
    "        optimizer.zero_grad()\n",
    "        output = model(pic)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_train += loss.item()*pic.size(0)\n",
    "    \n",
    "\n",
    "    # enable model to evaluate not train (turn off dropout)\n",
    "    model.eval()\n",
    "    # disable calculation gradient\n",
    "    with torch.no_grad():\n",
    "        for pic, target in loader_valid:\n",
    "           \n",
    "            if torch.cuda.is_available():\n",
    "                pic, target = pic.cuda(), target.cuda()\n",
    "            \n",
    "            output = model(pic)\n",
    "            loss = criterion(output, target)\n",
    "            loss_valid += loss.item()*pic.size(0)\n",
    "            \n",
    "            _, pred = torch.max(output, 1)\n",
    "            correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "            \n",
    "            for i in range(len(target)):\n",
    "                label = target.data[i]\n",
    "                class_correct[label] += correct[i].item()\n",
    "                class_total[label] += 1\n",
    "            \n",
    "    loss_train = loss_train/len(loader_train.sampler)\n",
    "    loss_valid = loss_valid/len(loader_valid.sampler)\n",
    "    \n",
    "    train_losses.append(loss_train)\n",
    "    valid_losses.append(loss_valid)\n",
    "\n",
    "    print(f\"Epoch: {epoch} \\tTraining Loss: {loss_train:.6f}\"\n",
    "          f\"\\tValidation Loss: {loss_valid:.6f}\")\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if loss_valid <= valid_loss_min:\n",
    "        print(f\"Validation loss decreased ({valid_loss_min:.6f} --> {loss_valid:.6f}).\"\n",
    "              \"Saving model ...\")\n",
    "        torch.save(model, \"data/model_MNIST_epoch90_SGD_002.pt\")\n",
    "        valid_loss_min = loss_valid\n",
    "        \n",
    "# # Print sumary\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            str(i), 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.axis([0, 100, 0, 0.3])\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNNModel(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1568, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"data/model_MNIST_epoch90_SGD_002.pt\")\n",
    "model = MyNNModel()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # we must get into list\n",
    "    for pic in loader_test:\n",
    "        pic = pic[0]\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            pic = pic.cuda()\n",
    "        \n",
    "        output = model(pic)\n",
    "        labels.append(torch.argmax(torch.exp(output).data).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create submission Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_dict = {'ImageId':list(range(1,len(loader_test.sampler) + 1)),'Label':labels}\n",
    "df_submission = pd.DataFrame.from_dict(submission_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 7], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission['Label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1]])\n",
      "tensor([[[[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.7373],\n",
      "          [1.0000],\n",
      "          [0.3686],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.7490],\n",
      "          [0.9804],\n",
      "          [0.9922],\n",
      "          [0.3647],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.4824],\n",
      "          [0.9725],\n",
      "          [0.9922],\n",
      "          [0.6549],\n",
      "          [0.0392],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.3137],\n",
      "          [0.9686],\n",
      "          [0.9922],\n",
      "          [0.8157],\n",
      "          [0.0510],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.1137],\n",
      "          [0.8118],\n",
      "          [0.9922],\n",
      "          [0.9216],\n",
      "          [0.3020],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.2118],\n",
      "          [0.8196],\n",
      "          [0.9922],\n",
      "          [0.9922],\n",
      "          [0.3451],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.3647],\n",
      "          [0.9961],\n",
      "          [0.9922],\n",
      "          [0.9333],\n",
      "          [0.6667],\n",
      "          [0.0667],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0902],\n",
      "          [0.8235],\n",
      "          [0.9961],\n",
      "          [0.9922],\n",
      "          [0.6235],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0627],\n",
      "          [0.8196],\n",
      "          [0.9922],\n",
      "          [0.9961],\n",
      "          [0.9412],\n",
      "          [0.3176],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.1059],\n",
      "          [0.9922],\n",
      "          [0.9922],\n",
      "          [0.9961],\n",
      "          [0.0510],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0784],\n",
      "          [0.8078],\n",
      "          [0.9961],\n",
      "          [0.9961],\n",
      "          [0.7765],\n",
      "          [0.0275],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.6588],\n",
      "          [0.9922],\n",
      "          [0.9922],\n",
      "          [0.7686],\n",
      "          [0.0275],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0784],\n",
      "          [0.7961],\n",
      "          [0.9922],\n",
      "          [0.9725],\n",
      "          [0.2980],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0863],\n",
      "          [0.7373],\n",
      "          [0.9922],\n",
      "          [0.9608],\n",
      "          [0.3647],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.4039],\n",
      "          [0.9922],\n",
      "          [0.9922],\n",
      "          [0.7490],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.3490],\n",
      "          [0.9412],\n",
      "          [0.9922],\n",
      "          [0.7647],\n",
      "          [0.0980],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0588],\n",
      "          [0.8627],\n",
      "          [0.9922],\n",
      "          [0.9922],\n",
      "          [0.3137],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.3686],\n",
      "          [0.9922],\n",
      "          [0.9922],\n",
      "          [0.9922],\n",
      "          [0.3686],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.3490],\n",
      "          [0.9843],\n",
      "          [0.9922],\n",
      "          [0.9804],\n",
      "          [0.5137],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.8392],\n",
      "          [0.8549],\n",
      "          [0.3725],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]],\n",
      "\n",
      "         [[0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000],\n",
      "          [0.0000]]]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for pic, label in trainloader:\n",
    "#     print(label)\n",
    "#     print(pic)\n",
    "#     plt.figure()\n",
    "#     image_array = pic\n",
    "#     plt.imshow(image_array.reshape(28,28))\n",
    "#     plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_array = X_train_norm[0]\n",
    "# plt.imshow(image_array.reshape(28,28), cmap='gray')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
