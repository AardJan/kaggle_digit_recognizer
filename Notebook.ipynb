{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transform(row_pandas_dataframe, y_hat, isTrain=True):\n",
    "    \n",
    "    if isTrain:\n",
    "        # DATA\n",
    "        X = row_pandas_dataframe.drop(columns=[y_hat])\n",
    "        # Convert to numpy.ndarray and change shape to 28x28x1\n",
    "        X = X.values.reshape(-1,28,28,1)\n",
    "        # Convert numpy.ndarrray to torch tensor\n",
    "        X = torch.from_numpy(X)\n",
    "        # Normalize step 1  change to [0 to 1]\n",
    "        X = torch.true_divide(X, 255)\n",
    "        # Normalize step 2 change to [-1 to 1]\n",
    "        X = torch.true_divide((X - 0.5), 0.5)\n",
    "\n",
    "        # LABELS\n",
    "        y = row_pandas_dataframe[y_hat]\n",
    "        # Transform to Tensor\n",
    "        y = torch.from_numpy(y.values)\n",
    "        # Reshape to one column and x row ([1, 2, 3] -> [[1], [2], [3]])\n",
    "        y = y.view(-1, 1)\n",
    "        # Change type of tensor\n",
    "        y.type(y.LongTensor)\n",
    "    \n",
    "        return y, X\n",
    "    \n",
    "    else:\n",
    "        # DATA\n",
    "        # Convert to numpy.ndarray and change shape to 28x28x1\n",
    "        X = row_pandas_dataframe.values.reshape(-1,28,28,1)\n",
    "        # Convert numpy.ndarrray to torch tensor\n",
    "        X = torch.from_numpy(X)\n",
    "        # Normalize step 1  change to [0 to 1]\n",
    "        X = torch.true_divide(X, 255)\n",
    "        # Normalize step 2 change to [-1 to 1]\n",
    "        X = torch.true_divide((X - 0.5), 0.5)\n",
    "        \n",
    "        return X    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"data/train.csv\")\n",
    "data_test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.utils.data.TensorDataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pic, label in trainloader:\n",
    "#     print(label)\n",
    "#     print(pic)\n",
    "#     plt.figure()\n",
    "#     image_array = pic\n",
    "#     plt.imshow(image_array.reshape(28,28))\n",
    "#     plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_array = X_train_norm[0]\n",
    "# plt.imshow(image_array.reshape(28,28), cmap='gray')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
